{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import Tensor, nn\n",
    "from torch.nn.functional import normalize\n",
    "import transformer_lens\n",
    "from transformer_lens import HookedTransformer\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from sparse_QK_trainer import SparseQK, train_sparse_QK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformer_lens.HookedTransformer.from_pretrained(\"gpt2\", fold_ln = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "import datasets\n",
    "dataset = datasets.load_dataset(\"NeelNanda/pile-10k\", split=\"train\")\n",
    "print(dataset)\n",
    "print(dataset[0]['text'][:100])\n",
    "tokens_dataset = transformer_lens.utils.tokenize_and_concatenate(dataset, model.tokenizer, streaming=False, max_length=20, column_name=\"text\", add_bos_token=True, num_proc=4)\n",
    "data_loader = t.utils.data.DataLoader(tokens_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\"d_hidden\": 4096,\n",
    "       \"l1_coeff\": 1e-6,\n",
    "       \"d_model\": 768,\n",
    "       \"n_heads\": 1,\n",
    "       \"d_head\": 64,\n",
    "       \"seed\": 87,\n",
    "       \"device\": \"cuda:0\",\n",
    "       \"dead_freq\": 1e-7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_model = train_sparse_QK(model, cfg, 1, 10, data_loader)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
